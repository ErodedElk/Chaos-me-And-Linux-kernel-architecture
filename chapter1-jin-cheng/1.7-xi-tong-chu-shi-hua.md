---
description: Chaos me|Linux kernel architecture chapter-1
---

# 1.7 系统初始化

前几节的内容已经描述了 Linux 中的进程模型，但美中不足的是，我们仍然对整个流程缺乏概念。所以本节中，笔者打算通过 Linux 系统的启动过程中对初始进程的创建过程总结一下前几节的内容。 希望各位看得愉快。

### 1.7.1 start\_kernel

以 Intel 的 IA-32 架构为例，内核启动需要经历从实模式到保护模式的转换。但在那个部分存在很多体系架构独立的操作，这并不是我们需要的重点，笔者打算从具备泛用性的代码 **start\_kernel** 函数开始，它是整个内核正式开始初始化时调用的函数。

实现如下，笔者已经做部分简化：

```c
asmlinkage __visible void __init __no_sanitize_address start_kernel(void)
{
	char *command_line;
	char *after_dashes;
	
	/*
	 * Interrupts are still disabled. Do necessary setups, then
	 * enable them.
	 */
	boot_cpu_init();
	page_address_init();
	setup_arch(&command_line);
	setup_boot_config();
	setup_command_line(command_line);
	setup_nr_cpu_ids();
	setup_per_cpu_areas();
	smp_prepare_boot_cpu();	/* arch-specific boot-cpu hooks */
	boot_cpu_hotplug_init();

	build_all_zonelists(NULL);
	page_alloc_init();

	/*
	 * These use large bootmem allocations and must precede
	 * kmem_cache_init()
	 */
	setup_log_buf(0);
	vfs_caches_init_early();
	sort_main_extable();
	trap_init();
	mm_init();

	ftrace_init();

	/*
	 * Set up the scheduler prior starting any interrupts (such as the
	 * timer interrupt). Full topology setup happens at smp_init()
	 * time - but meanwhile we still have a functioning scheduler.
	 */
	sched_init();

	/*
	 * Allow workqueue creation and work item queueing/cancelling
	 * early.  Work item execution depends on kthreads and starts after
	 * workqueue_init().
	 */
	workqueue_init_early();

	rcu_init();

	/* Trace events are available after this */
	trace_init();

	if (initcall_debug)
		initcall_debug_enable();

	context_tracking_init();
	/* init some links before init_ISA_irqs() */
	early_irq_init();
	init_IRQ();
	tick_init();
	rcu_init_nohz();
	init_timers();
	srcu_init();
	hrtimers_init();
	softirq_init();
	timekeeping_init();
	kfence_init();

	/*
	 * For best initial stack canary entropy, prepare it after:
	 * - setup_arch() for any UEFI RNG entropy and boot cmdline access
	 * - timekeeping_init() for ktime entropy used in rand_initialize()
	 * - rand_initialize() to get any arch-specific entropy like RDRAND
	 * - add_latent_entropy() to get any latent entropy
	 * - adding command line entropy
	 */
	rand_initialize();
	add_latent_entropy();
	add_device_randomness(command_line, strlen(command_line));
	boot_init_stack_canary();

	time_init();
	perf_event_init();
	profile_init();
	call_function_init();

	early_boot_irqs_disabled = false;
	local_irq_enable();

	kmem_cache_init_late();

	/*
	 * HACK ALERT! This is early. We're enabling the console before
	 * we've done PCI setups etc, and console_init() must be aware of
	 * this. But we do want output early, in case something goes wrong.
	 */
	console_init();
	
	lockdep_init();

	/*
	 * Need to run this when irqs are enabled, because it wants
	 * to self-test [hard/soft]-irqs on/off lock inversion bugs
	 * too:
	 */
	locking_selftest();

	/*
	 * This needs to be called before any devices perform DMA
	 * operations that might use the SWIOTLB bounce buffers. It will
	 * mark the bounce buffers as decrypted so that their usage will
	 * not cause "plain-text" data to be decrypted when accessed.
	 */
	mem_encrypt_init();

	setup_per_cpu_pageset();
	numa_policy_init();
	acpi_early_init();
	if (late_time_init)
		late_time_init();
	sched_clock_init();
	calibrate_delay();
	pid_idr_init();
	anon_vma_init();

	thread_stack_cache_init();
	cred_init();
	fork_init();
	proc_caches_init();
	uts_ns_init();
	key_init();
	security_init();
	dbg_late_init();
	vfs_caches_init();
	pagecache_init();
	signals_init();
	seq_file_init();
	proc_root_init();
	nsfs_init();
	cpuset_init();
	cgroup_init();
	taskstats_init_early();
	delayacct_init();

	poking_init();
	check_bugs();

	acpi_subsystem_init();
	arch_post_acpi_subsys_init();
	kcsan_init();

	/* Do the rest non-__init'ed, we're now alive */
	arch_call_rest_init();

	prevent_tail_call_optimization();
}
```

如您所见的是，整个函数充斥了各种各样的 **\*\_init** 函数, 大多数函数都不需要我们目前去关心，我们需要在意的第一个函数是其中名为 **sched\_init** 的函数。

#### 1.7.1.1 sched\_init

该函数用以初始化任务调度功能，笔者简化好仅保留了本节需要的内容：

```c
void __init sched_init(void)
{
   set_load_weight(&init_task, false);

   /*
    * Make us the idle thread. Technically, schedule() should not be
    * called from this thread, however somewhere below it might be,
    * but because we are the idle thread, we just pick up running again
    * when this runqueue becomes "idle".
    */
   init_idle(current, smp_processor_id());

   init_sched_fair_class();

   init_uclamp();

   scheduler_running = 1;
}
```

* set\_load\_weight：

> 该函数用以设置进程的优先级，注意到它的参数中包含了一个 **init\_task** 任务，该任务就是进程号 pid 为 0 的进程。

* init\_idle：

> 该函数会把当前正在运行的这个进程注册到 idle 队列中。此处注册的进程 current 就是指 **init\_task** ，当所有初始化完成以后，就会切换到用户模式由用户委派任务了，现在这个内核进程大多数时候就都用不上了，只有当操作系统没事做的时候才会考虑回来执行这个进程。 下一小节会讨论有关 **init\_task** 的内容。

* init\_sched\_fair\_class：

> 初始化完全公平调度器。调度器的具体内容并不在本章讨论，甚至不一定在本书讨论，此处仅和前几节照应。

* init\_uclamp：

> uclamp 指的是 **Utilization Clamping**，是 Linux 中的一种能够将用户空间有关任务状态的信息传递给内核调度器的机制，它并不在本章的讨论范围内，但考虑到有可能会有读者感兴趣，故作注记。

#### 1.7.1.2 init\_task

和其他进程不同的是，这个进程是通过代码手动定义出来的，它的生成不通过 fork 或者 clone，完整定义如下：

```c
 struct task_struct init_task
#ifdef CONFIG_ARCH_TASK_STRUCT_ON_STACK
	__init_task_data
#endif
	__aligned(L1_CACHE_BYTES)
= {
#ifdef CONFIG_THREAD_INFO_IN_TASK
	.thread_info	= INIT_THREAD_INFO(init_task),
	.stack_refcount	= REFCOUNT_INIT(1),
#endif
	.__state	= 0,
	.stack		= init_stack,
	.usage		= REFCOUNT_INIT(2),
	.flags		= PF_KTHREAD,
	.prio		= MAX_PRIO - 20,
	.static_prio	= MAX_PRIO - 20,
	.normal_prio	= MAX_PRIO - 20,
	.policy		= SCHED_NORMAL,
	.cpus_ptr	= &init_task.cpus_mask,
	.user_cpus_ptr	= NULL,
	.cpus_mask	= CPU_MASK_ALL,
	.nr_cpus_allowed= NR_CPUS,
	.mm		= NULL,
	.active_mm	= &init_mm,
	.restart_block	= {
		.fn = do_no_restart_syscall,
	},
	.se		= {
		.group_node 	= LIST_HEAD_INIT(init_task.se.group_node),
	},
	.rt		= {
		.run_list	= LIST_HEAD_INIT(init_task.rt.run_list),
		.time_slice	= RR_TIMESLICE,
	},
	.tasks		= LIST_HEAD_INIT(init_task.tasks),
#ifdef CONFIG_SMP
	.pushable_tasks	= PLIST_NODE_INIT(init_task.pushable_tasks, MAX_PRIO),
#endif
#ifdef CONFIG_CGROUP_SCHED
	.sched_task_group = &root_task_group,
#endif
	.ptraced	= LIST_HEAD_INIT(init_task.ptraced),
	.ptrace_entry	= LIST_HEAD_INIT(init_task.ptrace_entry),
	.real_parent	= &init_task,
	.parent		= &init_task,
	.children	= LIST_HEAD_INIT(init_task.children),
	.sibling	= LIST_HEAD_INIT(init_task.sibling),
	.group_leader	= &init_task,
	RCU_POINTER_INITIALIZER(real_cred, &init_cred),
	RCU_POINTER_INITIALIZER(cred, &init_cred),
	.comm		= INIT_TASK_COMM,
	.thread		= INIT_THREAD,
	.fs		= &init_fs,
	.files		= &init_files,
#ifdef CONFIG_IO_URING
	.io_uring	= NULL,
#endif
	.signal		= &init_signals,
	.sighand	= &init_sighand,
	.nsproxy	= &init_nsproxy,
	.pending	= {
		.list = LIST_HEAD_INIT(init_task.pending.list),
		.signal = {{0}}
	},
	.blocked	= {{0}},
	.alloc_lock	= __SPIN_LOCK_UNLOCKED(init_task.alloc_lock),
	.journal_info	= NULL,
	INIT_CPU_TIMERS(init_task)
	.pi_lock	= __RAW_SPIN_LOCK_UNLOCKED(init_task.pi_lock),
	.timer_slack_ns = 50000, /* 50 usec default slack */
	.thread_pid	= &init_struct_pid,
	.thread_group	= LIST_HEAD_INIT(init_task.thread_group),
	.thread_node	= LIST_HEAD_INIT(init_signals.thread_head),
#ifdef CONFIG_AUDIT
	.loginuid	= INVALID_UID,
	.sessionid	= AUDIT_SID_UNSET,
#endif
#ifdef CONFIG_PERF_EVENTS
	.perf_event_mutex = __MUTEX_INITIALIZER(init_task.perf_event_mutex),
	.perf_event_list = LIST_HEAD_INIT(init_task.perf_event_list),
#endif
#ifdef CONFIG_PREEMPT_RCU
	.rcu_read_lock_nesting = 0,
	.rcu_read_unlock_special.s = 0,
	.rcu_node_entry = LIST_HEAD_INIT(init_task.rcu_node_entry),
	.rcu_blocked_node = NULL,
#endif
#ifdef CONFIG_TASKS_RCU
	.rcu_tasks_holdout = false,
	.rcu_tasks_holdout_list = LIST_HEAD_INIT(init_task.rcu_tasks_holdout_list),
	.rcu_tasks_idle_cpu = -1,
#endif
#ifdef CONFIG_TASKS_TRACE_RCU
	.trc_reader_nesting = 0,
	.trc_reader_special.s = 0,
	.trc_holdout_list = LIST_HEAD_INIT(init_task.trc_holdout_list),
#endif
#ifdef CONFIG_CPUSETS
	.mems_allowed_seq = SEQCNT_SPINLOCK_ZERO(init_task.mems_allowed_seq,
						 &init_task.alloc_lock),
#endif
#ifdef CONFIG_RT_MUTEXES
	.pi_waiters	= RB_ROOT_CACHED,
	.pi_top_task	= NULL,
#endif
	INIT_PREV_CPUTIME(init_task)
#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
	.vtime.seqcount	= SEQCNT_ZERO(init_task.vtime_seqcount),
	.vtime.starttime = 0,
	.vtime.state	= VTIME_SYS,
#endif
#ifdef CONFIG_NUMA_BALANCING
	.numa_preferred_nid = NUMA_NO_NODE,
	.numa_group	= NULL,
	.numa_faults	= NULL,
#endif
#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
	.kasan_depth	= 1,
#endif
#ifdef CONFIG_KCSAN
	.kcsan_ctx = {
		.disable_count		= 0,
		.atomic_next		= 0,
		.atomic_nest_count	= 0,
		.in_flat_atomic		= false,
		.access_mask		= 0,
		.scoped_accesses	= {LIST_POISON1, NULL},
	},
#endif
#ifdef CONFIG_TRACE_IRQFLAGS
	.softirqs_enabled = 1,
#endif
#ifdef CONFIG_LOCKDEP
	.lockdep_depth = 0, /* no locks held yet */
	.curr_chain_key = INITIAL_CHAIN_KEY,
	.lockdep_recursion = 0,
#endif
#ifdef CONFIG_FUNCTION_GRAPH_TRACER
	.ret_stack		= NULL,
	.tracing_graph_pause	= ATOMIC_INIT(0),
#endif
#if defined(CONFIG_TRACING) && defined(CONFIG_PREEMPTION)
	.trace_recursion = 0,
#endif
#ifdef CONFIG_LIVEPATCH
	.patch_state	= KLP_UNDEFINED,
#endif
#ifdef CONFIG_SECURITY
	.security	= NULL,
#endif
#ifdef CONFIG_SECCOMP_FILTER
	.seccomp	= { .filter_count = ATOMIC_INIT(0) },
#endif
};
EXPORT_SYMBOL(init_task);
```

如您所见的是，这个进程通过代码在编译阶段就形成了，并且，注意到它的栈：

```c
	.stack		= init_stack,
```

**init\_stack** 是一个静态变量，它的本质是一个数组，定义如下：

```c
extern unsigned long init_stack[THREAD_SIZE / sizeof(unsigned long)];
```

因此，这个进程的内存空间并不是通过分配器获取的，如您所见，它的描述符、栈，以及一些其他成员也通过类似方法，在代码中直接声明。

#### 1.7.1.3 arch\_call\_rest\_init

该函数是一个外部接口，通过调用 **rest\_init** 函数完成，完整定义如下：

```c
noinline void __ref rest_init(void)
{
	struct task_struct *tsk;
	int pid;

	rcu_scheduler_starting();
	/*
	 * We need to spawn init first so that it obtains pid 1, however
	 * the init task will end up wanting to create kthreads, which, if
	 * we schedule it before we create kthreadd, will OOPS.
	 */
	pid = kernel_thread(kernel_init, NULL, CLONE_FS);
	/*
	 * Pin init on the boot CPU. Task migration is not properly working
	 * until sched_init_smp() has been run. It will set the allowed
	 * CPUs for init to the non isolated CPUs.
	 */
	rcu_read_lock();
	tsk = find_task_by_pid_ns(pid, &init_pid_ns);
	tsk->flags |= PF_NO_SETAFFINITY;
	set_cpus_allowed_ptr(tsk, cpumask_of(smp_processor_id()));
	rcu_read_unlock();

	numa_default_policy();
	pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
	rcu_read_lock();
	kthreadd_task = find_task_by_pid_ns(pid, &init_pid_ns);
	rcu_read_unlock();

	/*
	 * Enable might_sleep() and smp_processor_id() checks.
	 * They cannot be enabled earlier because with CONFIG_PREEMPTION=y
	 * kernel_thread() would trigger might_sleep() splats. With
	 * CONFIG_PREEMPT_VOLUNTARY=y the init task might have scheduled
	 * already, but it's stuck on the kthreadd_done completion.
	 */
	system_state = SYSTEM_SCHEDULING;

	complete(&kthreadd_done);

	/*
	 * The boot idle thread must execute schedule()
	 * at least once to get things moving:
	 */
	schedule_preempt_disabled();
	/* Call into cpu_idle with preempt disabled */
	cpu_startup_entry(CPUHP_ONLINE);
}
```

如下两行代码才是本节的关键：

```c
	pid = kernel_thread(kernel_init, NULL, CLONE_FS);
	pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);
```

第一行创建了一个内核线程，线程的执行流为 **kernel\_init** 函数，该线程的 PID 为 1； 第二行创建了一个内核线程，线程的执行流为 **kthreadd** 函数，该线程的 PID 为 2；

我们一直以来最关注的 init 进程就是此处的 **kernel\_init** 函数。而 **kernel\_thread** 函数则用于创建一个内核线程，其实现如下：

```c
pid_t kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)
{
	struct kernel_clone_args args = {
		.flags		= ((lower_32_bits(flags) | CLONE_VM |
				    CLONE_UNTRACED) & ~CSIGNAL),
		.exit_signal	= (lower_32_bits(flags) & CSIGNAL),
		.stack		= (unsigned long)fn,
		.stack_size	= (unsigned long)arg,
	};

	return kernel_clone(&args);
}
```

至于 kernel\_clone ，笔者已在 1.5 小节提及，因此这里不做赘述。我们来关注 init 的内容。

#### 1.7.1.4 kernel\_init

笔者简化了该函数以方便读者阅读：

```c
static int __ref kernel_init(void *unused)
{
	int ret;

	kernel_init_freeable();

	system_state = SYSTEM_FREEING_INITMEM;
	kprobe_free_init_mem();
	ftrace_free_init_mem();
	kgdb_free_init_mem();
	exit_boot_config();
	free_initmem();
	mark_readonly();

	system_state = SYSTEM_RUNNING;
	numa_default_policy();

	rcu_end_inkernel_boot();

	do_sysctl_args();

	if (ramdisk_execute_command) {
		ret = run_init_process(ramdisk_execute_command);
		if (!ret)
			return 0;
	}

	/*
	 * We try each of these until one succeeds.
	 *
	 * The Bourne shell can be used instead of init if we are
	 * trying to recover a really broken machine.
	 */
	if (execute_command) {
		ret = run_init_process(execute_command);
		if (!ret)
			return 0;
	}

	if (!try_to_run_init_process("/sbin/init") ||
	    !try_to_run_init_process("/etc/init") ||
	    !try_to_run_init_process("/bin/init") ||
	    !try_to_run_init_process("/bin/sh"))
		return 0;
}
```

除了上半部分的大量初始化函数外，最显眼的莫过于下方几个 **run\_init\_process** 函数。 该函数通过调用 **kernel\_execve** 完成工作。

简化后的函数实现如下：

```c
int kernel_execve(const char *kernel_filename,
		  const char *const *argv, const char *const *envp)
{
	struct filename *filename;
	struct linux_binprm *bprm;
	int fd = AT_FDCWD;
	int retval;

	filename = getname_kernel(kernel_filename);

	bprm = alloc_bprm(fd, filename);

	retval = count_strings_kernel(argv);
	bprm->argc = retval;

	retval = count_strings_kernel(envp);
	bprm->envc = retval;

	retval = bprm_stack_limits(bprm);

	retval = copy_string_kernel(bprm->filename, bprm);
	bprm->exec = bprm->p;

	retval = copy_strings_kernel(bprm->envc, envp, bprm);

	retval = copy_strings_kernel(bprm->argc, argv, bprm);

	retval = bprm_execve(bprm, fd, filename, 0);
out_ret:
	putname(filename);
	return retval;
}
```

* 根据文件名创建 **linux\_binprm** 结构体
* 然后为该文件传递参数和环境变量
* 执行该二进制文件(bprm\_execve)

**bprm\_execve** 函数会让内存中的二进制文件通过调用 **sched\_exec** 选择一个最合适的处理器将任务迁移过去，然后通过 **exec\_binprm** 函数进行具体的执行。

> 顺带一提的是，**exec\_binprm** 函数中会调用 **search\_binary\_handler** 来判断文件的类型，然后调用 **load\_binary** 加载二进制数据。这个 **load\_binary** 是一个函数指针，它会根据不同的文件类型选择不同的函数，例如，对于 ELF 文件，它会调用 **load\_elf\_binary** 函数。 另外，**linux\_binprm** 意为 **linux\_binary\_program**，即 Linux 二进制程序。

如您所见，内核会尝试加载几个 init 程序，最终启动一个 sh 窗口。最终，当必要的初始化工作完成以后，调度器会优先选出这下程序开始执行，最终留下一个 sh 以供用户进行交互。 不过需要注意的是，那几个二进制文件只需要有一个成功执行即可。 如果以 Ubuntu 为例，执行的 **/sbin/init** 程序会启动自己的 shell

### 1.7.2 值得关注的地方

不知道您是否在意过，kernel\_init 是否会被返回？以及，上述几个操作结束以后，就应该留下一个用户态的 shell 以供交互，但这个状态切换又是发生在哪一步呢？

首先是第一个问题，kernel\_init 当然有可能返回，但它返回以后又会再次调用：

```c
     kernel_thread(kernel_init, NULL, CLONE_FS | CLONE_SIGHAND);
```

但你应该注意到，它传递了两个 **CLONE** 参数，表示新进程会复制当前进程的用户空间上下文。倘若当前进程已经是用户空间的程序了，那么新进程自然也会如此。因此切换模式的过程应该发生在 **execve** 中。此处对应于 **kernel\_execve** 函数

而回顾进程切换的流程，我们知道，**execve** 调用会改变 **pt\_regs** ，当任务被调度时通过 **iret** 发生权级切换。如果您对具体的过程感兴趣，可以查阅一下 **switch\_to** 函数。

以及另外一个你可以会感兴趣的知识是，PID 为 2 的那个进程，其父进程ID，即 PPID 为 0。 因为这个进程也是内核进程，它和 init 进程是平级的，因此其只能以内核本身为父进程。 只不过该进程主要用于维护内核调度器，并不在本章的讨论范围内，因此笔者不过多赘述。

### 1.7.3 参考资料

* Linux内核中的init\_task进程和idle进程 https://blog.krybot.com/a?ID=00200-2329e9ce-9839-4472-8973-41e1dedd16da
* Linux Kernel - 编程起点和各模块简述 http://www.dosrc.com/mark/linux-3.18.6/2016/03/17/linux-kernel-construct-a-simple-linux-operating-system.html
* Linux i386 引导代码 HOWTO https://tldp.org/HOWTO/Linux-i386-Boot-Code-HOWTO/init\_main.html
* how do we launch our programs? https://0xax.gitbooks.io/linux-insides/content/SysCall/linux-syscall-4.html
* Al Viro's new execve/kernel\_thread design https://lwn.net/Articles/520227/
* kthreadd-linux下2号进程 https://www.cnblogs.com/embedded-linux/p/6618717.html
